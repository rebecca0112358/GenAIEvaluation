{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f86c1e4c-73f0-4166-9e85-568f49124d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Reference Compound: 0.055699999999999986\n",
      "ğŸ“Š New ICD Compound: -0.26715\n",
      "\n",
      "ğŸ¯ Bias/Fairness Score: 57.0/100\n",
      "ğŸ” Sentiment Deviation: 0.323\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¦ Install required packages\n",
    "import sys\n",
    "!{sys.executable} -m pip install --quiet python-docx nltk matplotlib\n",
    "\n",
    "# ğŸ“š Imports\n",
    "import docx\n",
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "nltk.download(\"vader_lexicon\", quiet=True)\n",
    "\n",
    "# ğŸ“‚ File paths (update as needed)\n",
    "reference_icd_path = r\"C:\\Users\\rjone\\OneDrive - Waterworksai.com\\PharmaDS\\NewShortCourseMaterials\\VanderbiltICD_SLE_Cognitive.docx\"\n",
    "new_icd_path = r\"C:\\Users\\rjone\\OneDrive - Waterworksai.com\\PharmaDS\\NewShortCourseMaterials\\SampleStudyDocuments\\icdv1.docx\"\n",
    "\n",
    "# ğŸ“˜ Load DOCX\n",
    "def read_docx(filepath):\n",
    "    doc = docx.Document(filepath)\n",
    "    return \"\\n\".join(p.text for p in doc.paragraphs)\n",
    "\n",
    "# ğŸ§  Sentiment analysis\n",
    "def analyze_sentiment(text):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    return [(s, analyzer.polarity_scores(s)) for s in sentences]\n",
    "\n",
    "# ğŸ” Filter by keywords\n",
    "def filter_sentences(sentences, keywords):\n",
    "    return [(s, score) for s, score in sentences if any(k.lower() in s.lower() for k in keywords)]\n",
    "\n",
    "# ğŸ“Š Average sentiment\n",
    "def average_sentiment(sentences):\n",
    "    avg = {\"neg\": 0, \"neu\": 0, \"pos\": 0, \"compound\": 0}\n",
    "    if not sentences:\n",
    "        return avg\n",
    "    for _, scores in sentences:\n",
    "        for key in avg:\n",
    "            avg[key] += scores[key]\n",
    "    return {k: v / len(sentences) for k, v in avg.items()}\n",
    "\n",
    "# ğŸ¯ Bias/Fairness scoring\n",
    "def compute_bias_fairness(compound_ref, compound_new, max_deviation=0.75):\n",
    "    deviation = abs(compound_new - compound_ref)\n",
    "    score = max(0, 100 - (deviation / max_deviation * 100))\n",
    "    return round(score, 1), deviation\n",
    "\n",
    "# ğŸ“ˆ Plotting\n",
    "def plot_sentiment_comparison(reference_filtered, new_filtered):\n",
    "    ref_scores = [s[1]['compound'] for s in reference_filtered]\n",
    "    new_scores = [s[1]['compound'] for s in new_filtered]\n",
    "    max_len = max(len(ref_scores), len(new_scores))\n",
    "    ref_scores += [np.nan] * (max_len - len(ref_scores))\n",
    "    new_scores += [np.nan] * (max_len - len(new_scores))\n",
    "    labels = [f\"S{i+1}\" for i in range(max_len)]\n",
    "    \n",
    "    x = range(max_len)\n",
    "    width = 0.35\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.bar([i - width/2 for i in x], ref_scores, width, label='Reference ICD', color='skyblue')\n",
    "    plt.bar([i + width/2 for i in x], new_scores, width, label='New ICD', color='salmon')\n",
    "\n",
    "    plt.axhline(0, color='gray', linestyle='--')\n",
    "    plt.xticks(x, labels, rotation=45)\n",
    "    plt.ylabel(\"Compound Sentiment Score\")\n",
    "    plt.title(\"Risk/Benefit Sentence Sentiment Comparison\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ğŸš€ Main execution\n",
    "reference_text = read_docx(reference_icd_path)\n",
    "new_text = read_docx(new_icd_path)\n",
    "\n",
    "reference_sentences = analyze_sentiment(reference_text)\n",
    "new_sentences = analyze_sentiment(new_text)\n",
    "\n",
    "keywords = [\"risk\", \"benefit\", \"adverse\", \"side effect\", \"safety\", \"hazard\"]\n",
    "reference_filtered = filter_sentences(reference_sentences, keywords)\n",
    "new_filtered = filter_sentences(new_sentences, keywords)\n",
    "\n",
    "reference_avg = average_sentiment(reference_filtered)\n",
    "new_avg = average_sentiment(new_filtered)\n",
    "\n",
    "print(\"ğŸ“Š Reference Compound:\", reference_avg['compound'])\n",
    "print(\"ğŸ“Š New ICD Compound:\", new_avg['compound'])\n",
    "\n",
    "fairness_score, deviation = compute_bias_fairness(reference_avg['compound'], new_avg['compound'])\n",
    "\n",
    "print(f\"\\nğŸ¯ Bias/Fairness Score: {fairness_score}/100\")\n",
    "print(f\"ğŸ” Sentiment Deviation: {deviation:.3f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711a131a-b630-44e4-b453-c8118ba39d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (py311_env)",
   "language": "python",
   "name": "py311_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
